{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizer v2\n",
    "\n",
    "- Fine Tuning Base Model: Llama 3.2 (1B)\n",
    "- Dataset: Dialogue Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:49:14.994251Z",
     "iopub.status.busy": "2024-11-20T19:49:14.993908Z",
     "iopub.status.idle": "2024-11-20T19:53:19.382328Z",
     "shell.execute_reply": "2024-11-20T19:53:19.381070Z",
     "shell.execute_reply.started": "2024-11-20T19:49:14.994221Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:56:03.725823Z",
     "iopub.status.busy": "2024-11-20T19:56:03.724903Z",
     "iopub.status.idle": "2024-11-20T19:56:03.731341Z",
     "shell.execute_reply": "2024-11-20T19:56:03.730504Z",
     "shell.execute_reply.started": "2024-11-20T19:56:03.725777Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Summarizer_v1\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"\"\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model in 4 bit and Specify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:55:07.849040Z",
     "iopub.status.busy": "2024-11-20T19:55:07.848716Z",
     "iopub.status.idle": "2024-11-20T19:55:27.253180Z",
     "shell.execute_reply": "2024-11-20T19:55:27.252245Z",
     "shell.execute_reply.started": "2024-11-20T19:55:07.849009Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.3.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54edc829d50d4344bb15c7704f08b637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.03G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406a4315a20341de9c4c8ca8a8b056a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/121 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e4c96ad4ae64a9db06c4a01ef19d227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/50.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3fba836e534cbfb4aa26dc193999ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0549b57240146cf9a631a0651555355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/459 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.7 patched 16 layers with 16 QKV layers, 16 O layers and 16 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-1B-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Map it with the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:55:32.702084Z",
     "iopub.status.busy": "2024-11-20T19:55:32.701312Z",
     "iopub.status.idle": "2024-11-20T19:55:33.002245Z",
     "shell.execute_reply": "2024-11-20T19:55:33.001261Z",
     "shell.execute_reply.started": "2024-11-20T19:55:32.702051Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# output_dir = \"/kaggle/working/\"\n",
    "train_data_path = '/kaggle/input/summarization/dialogue_summary_01/dialogue_summary_train.csv'\n",
    "val_data_path = '/kaggle/input/summarization/dialogue_summary_01/dialogue_summary_validation.csv'\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:55:35.489864Z",
     "iopub.status.busy": "2024-11-20T19:55:35.489210Z",
     "iopub.status.idle": "2024-11-20T19:55:35.513723Z",
     "shell.execute_reply": "2024-11-20T19:55:35.512532Z",
     "shell.execute_reply.started": "2024-11-20T19:55:35.489831Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...</td>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "      <td>get a check-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#: Hello Mrs. Parker, how have you bee...</td>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "      <td>vaccines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#: Excuse me, did you see a set of key...</td>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "      <td>find keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#: Why didn't you tell me you had a gi...</td>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "      <td>have a girlfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1#: Watsup, ladies! Y'll looking'fine t...</td>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...   \n",
       "1  #Person1#: Hello Mrs. Parker, how have you bee...   \n",
       "2  #Person1#: Excuse me, did you see a set of key...   \n",
       "3  #Person1#: Why didn't you tell me you had a gi...   \n",
       "4  #Person1#: Watsup, ladies! Y'll looking'fine t...   \n",
       "\n",
       "                                             summary              topic  \n",
       "0  Mr. Smith's getting a check-up, and Doctor Haw...     get a check-up  \n",
       "1  Mrs Parker takes Ricky for his vaccines. Dr. P...           vaccines  \n",
       "2  #Person1#'s looking for a set of keys and asks...          find keys  \n",
       "3  #Person1#'s angry because #Person2# didn't tel...  have a girlfriend  \n",
       "4  Malik invites Nikki to dance. Nikki agrees if ...              dance  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:55:39.124604Z",
     "iopub.status.busy": "2024-11-20T19:55:39.124291Z",
     "iopub.status.idle": "2024-11-20T19:55:39.133459Z",
     "shell.execute_reply": "2024-11-20T19:55:39.132443Z",
     "shell.execute_reply.started": "2024-11-20T19:55:39.124577Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person1#: Hello, how are you doing today?\\n#P...</td>\n",
       "      <td>#Person2# has trouble breathing. The doctor as...</td>\n",
       "      <td>see a doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#: Hey Jimmy. Let's go workout later t...</td>\n",
       "      <td>#Person1# invites Jimmy to go workout and pers...</td>\n",
       "      <td>do exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#: I need to stop eating such unhealth...</td>\n",
       "      <td>#Person1# plans to stop eating unhealthy foods...</td>\n",
       "      <td>healthy foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#: Do you believe in UFOs?\\n#Person2#:...</td>\n",
       "      <td>#Person2# believes in UFOs and can see them in...</td>\n",
       "      <td>UFOs and aliens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1#: Did you go to school today?\\n#Perso...</td>\n",
       "      <td>#Person1# didn't go to school today. #Person2#...</td>\n",
       "      <td>go to school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  #Person1#: Hello, how are you doing today?\\n#P...   \n",
       "1  #Person1#: Hey Jimmy. Let's go workout later t...   \n",
       "2  #Person1#: I need to stop eating such unhealth...   \n",
       "3  #Person1#: Do you believe in UFOs?\\n#Person2#:...   \n",
       "4  #Person1#: Did you go to school today?\\n#Perso...   \n",
       "\n",
       "                                             summary            topic  \n",
       "0  #Person2# has trouble breathing. The doctor as...     see a doctor  \n",
       "1  #Person1# invites Jimmy to go workout and pers...      do exercise  \n",
       "2  #Person1# plans to stop eating unhealthy foods...    healthy foods  \n",
       "3  #Person2# believes in UFOs and can see them in...  UFOs and aliens  \n",
       "4  #Person1# didn't go to school today. #Person2#...     go to school  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:56:14.085046Z",
     "iopub.status.busy": "2024-11-20T19:56:14.084361Z",
     "iopub.status.idle": "2024-11-20T19:56:14.427794Z",
     "shell.execute_reply": "2024-11-20T19:56:14.427038Z",
     "shell.execute_reply.started": "2024-11-20T19:56:14.085014Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a26f65257a48a4b720a7d3115d71a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9b74fbdec4d402296cd049e3d0dc807",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Below is a dialogue. Generate an abstractive summary and a topic for the dialogue.\n",
    "\n",
    "### Dialogue:\n",
    "{}\n",
    "\n",
    "### Summary and Topic:\n",
    "Summary: {}\n",
    "Topic: {}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    dialogues = examples[\"dialogue\"]\n",
    "    summaries = examples[\"summary\"]\n",
    "    topics = examples[\"topic\"]\n",
    "    \n",
    "    texts = []\n",
    "    for dialogue, summary, topic in zip(dialogues, summaries, topics):\n",
    "        # Construct the prompt for training\n",
    "        input_text = dialogue\n",
    "        output_text = f\"Summary: {summary} Topic: {topic}\"\n",
    "        \n",
    "        # Ensure that EOS_TOKEN is added to avoid infinite generation\n",
    "        text = prompt.format(input_text, summary, topic) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "\n",
    "# Convert the pandas DataFrame to the Hugging Face dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Apply the same transformation to the validation dataset\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "val_dataset = val_dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:56:22.713094Z",
     "iopub.status.busy": "2024-11-20T19:56:22.712481Z",
     "iopub.status.idle": "2024-11-20T19:56:22.718089Z",
     "shell.execute_reply": "2024-11-20T19:56:22.717122Z",
     "shell.execute_reply.started": "2024-11-20T19:56:22.713061Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\", 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\", 'topic': 'get a check-up', 'text': \"Below is a dialogue. Generate an abstractive summary and a topic for the dialogue.\\n\\n### Dialogue:\\n#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\\n\\n### Summary and Topic:\\nSummary: Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\\nTopic: get a check-up\\n<|end_of_text|>\"}\n",
      "{'dialogue': \"#Person1#: Hello, how are you doing today?\\n#Person2#: I ' Ve been having trouble breathing lately.\\n#Person1#: Have you had any type of cold lately?\\n#Person2#: No, I haven ' t had a cold. I just have a heavy feeling in my chest when I try to breathe.\\n#Person1#: Do you have any allergies that you know of?\\n#Person2#: No, I don ' t have any allergies that I know of.\\n#Person1#: Does this happen all the time or mostly when you are active?\\n#Person2#: It happens a lot when I work out.\\n#Person1#: I am going to send you to a pulmonary specialist who can run tests on you for asthma.\\n#Person2#: Thank you for your help, doctor.\", 'summary': '#Person2# has trouble breathing. The doctor asks #Person2# about it and will send #Person2# to a pulmonary specialist.', 'topic': 'see a doctor', 'text': \"Below is a dialogue. Generate an abstractive summary and a topic for the dialogue.\\n\\n### Dialogue:\\n#Person1#: Hello, how are you doing today?\\n#Person2#: I ' Ve been having trouble breathing lately.\\n#Person1#: Have you had any type of cold lately?\\n#Person2#: No, I haven ' t had a cold. I just have a heavy feeling in my chest when I try to breathe.\\n#Person1#: Do you have any allergies that you know of?\\n#Person2#: No, I don ' t have any allergies that I know of.\\n#Person1#: Does this happen all the time or mostly when you are active?\\n#Person2#: It happens a lot when I work out.\\n#Person1#: I am going to send you to a pulmonary specialist who can run tests on you for asthma.\\n#Person2#: Thank you for your help, doctor.\\n\\n### Summary and Topic:\\nSummary: #Person2# has trouble breathing. The doctor asks #Person2# about it and will send #Person2# to a pulmonary specialist.\\nTopic: see a doctor\\n<|end_of_text|>\"}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "print(val_dataset[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T19:56:30.937641Z",
     "iopub.status.busy": "2024-11-20T19:56:30.936805Z",
     "iopub.status.idle": "2024-11-20T19:56:30.963693Z",
     "shell.execute_reply": "2024-11-20T19:56:30.962823Z",
     "shell.execute_reply.started": "2024-11-20T19:56:30.937599Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a dialogue. Generate an abstractive summary and a topic for the dialogue.\n",
      "\n",
      "### Dialogue:\n",
      "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
      "#Person2#: I found it would be a good idea to get a check-up.\n",
      "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
      "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
      "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
      "#Person2#: Ok.\n",
      "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
      "#Person2#: Yes.\n",
      "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
      "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
      "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
      "#Person2#: Ok, thanks doctor.\n",
      "\n",
      "### Summary and Topic:\n",
      "Summary: Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n",
      "Topic: get a check-up\n",
      "<|end_of_text|>\n",
      "Below is a dialogue. Generate an abstractive summary and a topic for the dialogue.\n",
      "\n",
      "### Dialogue:\n",
      "#Person1#: Hello, how are you doing today?\n",
      "#Person2#: I ' Ve been having trouble breathing lately.\n",
      "#Person1#: Have you had any type of cold lately?\n",
      "#Person2#: No, I haven ' t had a cold. I just have a heavy feeling in my chest when I try to breathe.\n",
      "#Person1#: Do you have any allergies that you know of?\n",
      "#Person2#: No, I don ' t have any allergies that I know of.\n",
      "#Person1#: Does this happen all the time or mostly when you are active?\n",
      "#Person2#: It happens a lot when I work out.\n",
      "#Person1#: I am going to send you to a pulmonary specialist who can run tests on you for asthma.\n",
      "#Person2#: Thank you for your help, doctor.\n",
      "\n",
      "### Summary and Topic:\n",
      "Summary: #Person2# has trouble breathing. The doctor asks #Person2# about it and will send #Person2# to a pulmonary specialist.\n",
      "Topic: see a doctor\n",
      "<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['text'][0])\n",
    "print(val_dataset['text'][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:01:06.921497Z",
     "iopub.status.busy": "2024-11-20T20:01:06.920741Z",
     "iopub.status.idle": "2024-11-20T20:01:13.034872Z",
     "shell.execute_reply": "2024-11-20T20:01:13.034191Z",
     "shell.execute_reply.started": "2024-11-20T20:01:06.921461Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b49b12144884b1d95a548e686a9b00b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e973913916bc4d3ba1a9001df4cda4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# exist_already = os.path.exists(output_dir)\n",
    "output_dir = \"/kaggle/working/\"\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = True,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 10,\n",
    "        num_train_epochs = 1,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = output_dir,\n",
    "        save_strategy = \"steps\",\n",
    "        save_steps = 5,\n",
    "        eval_steps= 10,\n",
    "        save_total_limit = 2,\n",
    "        report_to=\"wandb\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# if(exist_already):\n",
    "#   trainer_stats = trainer.train(resume_from_checkpoint=True)\n",
    "# else:\n",
    "    # trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:01:16.387628Z",
     "iopub.status.busy": "2024-11-20T20:01:16.387271Z",
     "iopub.status.idle": "2024-11-20T20:32:13.856947Z",
     "shell.execute_reply": "2024-11-20T20:32:13.856090Z",
     "shell.execute_reply.started": "2024-11-20T20:01:16.387598Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,601 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 16 | Total steps = 100\n",
      " \"-____-\"     Number of trainable parameters = 11,272,192\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='100' max='100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [100/100 30:35, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.710800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.644300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.602700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.599800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.568400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.564800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.552300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.549300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.536500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.551100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:34:17.908486Z",
     "iopub.status.busy": "2024-11-20T20:34:17.908001Z",
     "iopub.status.idle": "2024-11-20T20:34:18.441082Z",
     "shell.execute_reply": "2024-11-20T20:34:18.440252Z",
     "shell.execute_reply.started": "2024-11-20T20:34:17.908451Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/llama_3_2_1B_summarizer_v2/tokenizer_config.json',\n",
       " '/kaggle/working/llama_3_2_1B_summarizer_v2/special_tokens_map.json',\n",
       " '/kaggle/working/llama_3_2_1B_summarizer_v2/tokenizer.json')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/kaggle/working/llama_3_2_1B_summarizer_v2\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/llama_3_2_1B_summarizer_v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:40:59.459130Z",
     "iopub.status.busy": "2024-11-20T20:40:59.458362Z",
     "iopub.status.idle": "2024-11-20T20:40:59.465788Z",
     "shell.execute_reply": "2024-11-20T20:40:59.465026Z",
     "shell.execute_reply.started": "2024-11-20T20:40:59.459093Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the model and prepare it for inference (only done once)\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "def generate_summary(user_input, max_new_tokens=256):\n",
    "    # Preprocess the input to fit the prompt format\n",
    "    summarization_prompt = \"\"\"Below is a dialogue. Generate an abstractive summary and a topic for the dialogue.\n",
    "\n",
    "        ### Dialogue:\n",
    "        {}\n",
    "        \n",
    "        ### Summary and Topic:\n",
    "        \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            summarization_prompt.format(user_input)  # Insert the user input (article) into the prompt\n",
    "        ], return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")  # Move inputs to GPU if available\n",
    "\n",
    "    # Initialize the text streamer to handle model output\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "    # Generate the summary\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        streamer=text_streamer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        use_cache=True,\n",
    "        temperature=0.4,  # randomness\n",
    "        top_p=0.9,  # nucleus sampling for better coherence\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:48:40.996818Z",
     "iopub.status.busy": "2024-11-20T20:48:40.995978Z",
     "iopub.status.idle": "2024-11-20T20:48:41.005074Z",
     "shell.execute_reply": "2024-11-20T20:48:41.004159Z",
     "shell.execute_reply.started": "2024-11-20T20:48:40.996783Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_summary(user_input, max_new_tokens=256):\n",
    "    # Preprocess the input to fit the prompt format\n",
    "    summarization_prompt = \"\"\"Below is a dialogue. Generate only an abstractive summary and a topic for the dialogue (without including the dialogue in the response).\n",
    "\n",
    "### Dialogue:\n",
    "{}\n",
    "        \n",
    "### Summary and Topic:\n",
    "Summary: \n",
    "Topic: \n",
    "\"\"\"\n",
    "\n",
    "    # Tokenize the input with the formatted prompt\n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            summarization_prompt.format(user_input)  # Insert the user input (dialogue) into the prompt\n",
    "        ], return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")  # Move inputs to GPU if available\n",
    "\n",
    "    # Generate the output\n",
    "    output = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        use_cache=True,\n",
    "        temperature=0.4,  # randomness\n",
    "        top_p=0.9,  # nucleus sampling for better coherence\n",
    "    )\n",
    "\n",
    "    # Decode the output tokens to get the text result\n",
    "    generated_output = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "\n",
    "    # Clean the output to remove the dialogue and keep only summary and topic\n",
    "    clean_output_text = clean_output(generated_output)\n",
    "    \n",
    "    return clean_output_text\n",
    "\n",
    "def clean_output(output_text):\n",
    "    # We only want the summary and topic, not the dialogue or prompt\n",
    "    # Strip the prompt instructions and any dialogue part\n",
    "    summary_start = \"Summary:\"\n",
    "    topic_start = \"Topic:\"\n",
    "    \n",
    "    summary_pos = output_text.find(summary_start)\n",
    "    topic_pos = output_text.find(topic_start)\n",
    "    \n",
    "    if summary_pos != -1 and topic_pos != -1:\n",
    "        summary_text = output_text[summary_pos + len(summary_start): topic_pos].strip()\n",
    "        topic_text = output_text[topic_pos + len(topic_start):].strip()\n",
    "        return f\"Summary: {summary_text}\\nTopic: {topic_text}\"\n",
    "    \n",
    "    return output_text.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:48:43.696348Z",
     "iopub.status.busy": "2024-11-20T20:48:43.695582Z",
     "iopub.status.idle": "2024-11-20T20:48:51.506460Z",
     "shell.execute_reply": "2024-11-20T20:48:51.505528Z",
     "shell.execute_reply.started": "2024-11-20T20:48:43.696308Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: \n",
      "Topic: Summary: \n",
      "Topic: \n",
      "Summary: #Deepak# is feeling overwhelmed and overwhelmed at work. #SurvUday# listens and supports #Deepak#.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "Topic: support\n",
      "Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "user_input = \"\"\"\n",
    "#Deepak#: \"I've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me.\"\n",
    "#SurvUday#: \"Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on?\"\n",
    "#Deepak#: \"I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me.\"\n",
    "#SurvUday#: \"I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work?\"\n",
    "#Deepak#: \"Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being.\"\n",
    "#SurvUday#: \"It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload?\"\n",
    "#Deepak#: \"I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle.\"\n",
    "#SurvUday#: \"It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together.\"\n",
    "#Deepak#: \"You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable?\"\n",
    "#SurvUday#: \"It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this.\"\n",
    "#Deepak#: \"Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance.\"\n",
    "#SurvUday#: \"You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this!\"\n",
    "\"\"\"\n",
    "\n",
    "# Call the function to generate the summary and topic\n",
    "print(generate_summary(user_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T20:41:44.873342Z",
     "iopub.status.busy": "2024-11-20T20:41:44.872993Z",
     "iopub.status.idle": "2024-11-20T20:41:49.218950Z",
     "shell.execute_reply": "2024-11-20T20:41:49.217980Z",
     "shell.execute_reply.started": "2024-11-20T20:41:44.873310Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is a dialogue. Generate **only** an abstractive summary and a topic for the dialogue, without including the dialogue itself in the output.\n",
      "\n",
      "        ### Dialogue:\n",
      "        \n",
      "#Deepak#: \"\"I've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me. \"\"\n",
      "#SurvUday#: \"\"Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on? \"\"\n",
      "#Deepak#: \"\"I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me. \"\"\n",
      "#SurvUday#: \"\"I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work? \"\"\n",
      "#Deepak#: \"\"Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being. \"\"\n",
      "#SurvUday#: \"\"It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload? \"\"\n",
      "#Deepak#: \"\"I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle. \"\"\n",
      "#SurvUday#: \"\"It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together. \"\"\n",
      "#Deepak#: \"\"You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable? \"\"\n",
      "#SurvUday#: \"\"It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this. \"\"\n",
      "#Deepak#: \"\"Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance. \"\"\n",
      "#SurvUday#: \"\"You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this! \"\"\n",
      "\n",
      "        \n",
      "        ### Summary and Topic:\n",
      "        Summary: \n",
      "        Topic: \n",
      "         Dialogue: #Deepak# is feeling sad and overwhelmed lately. #SurvUday# listens and supports #Deepak#.\n",
      "        Topic: support\n",
      "        Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "        Topic: support\n",
      "        Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a healthier balance.\n",
      "        Topic: support\n",
      "        Summary: #SurvUday# encourages #Deepak# to take care of #Deepak#'s well-being and find a\n"
     ]
    }
   ],
   "source": [
    "user_input = \"\"\"\n",
    "#Deepak#: \"\"I've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me. \"\"\n",
    "#SurvUday#: \"\"Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on? \"\"\n",
    "#Deepak#: \"\"I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me. \"\"\n",
    "#SurvUday#: \"\"I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work? \"\"\n",
    "#Deepak#: \"\"Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being. \"\"\n",
    "#SurvUday#: \"\"It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload? \"\"\n",
    "#Deepak#: \"\"I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle. \"\"\n",
    "#SurvUday#: \"\"It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together. \"\"\n",
    "#Deepak#: \"\"You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable? \"\"\n",
    "#SurvUday#: \"\"It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this. \"\"\n",
    "#Deepak#: \"\"Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance. \"\"\n",
    "#SurvUday#: \"\"You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this! \"\"\n",
    "\"\"\"\n",
    "generate_summary(user_input, max_new_tokens=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Model to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Token = \"\" # Huggingface Token\n",
    "Repo = \"dkp2701/summarizer_v2\" # Model Repo\n",
    "model.push_to_hub_gguf(Repo,\n",
    "                        tokenizer,\n",
    "                        quantization_method = [\"q4_k_m\"],\n",
    "                        token = Token)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6130639,
     "sourceId": 9965968,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
