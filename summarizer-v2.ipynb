{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizer v3\n",
    "\n",
    "- Fine Tuning Base Model: Llama 3.2 (3B)\n",
    "- \n",
    "Dataset: Dialogue Dataset from Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:25:24.853969Z",
     "iopub.status.busy": "2024-11-20T21:25:24.853031Z",
     "iopub.status.idle": "2024-11-20T21:27:28.129303Z",
     "shell.execute_reply": "2024-11-20T21:27:28.128322Z",
     "shell.execute_reply.started": "2024-11-20T21:25:24.853911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install pip3-autoremove\n",
    "!pip-autoremove torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio xformers --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install unsloth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:27:37.221820Z",
     "iopub.status.busy": "2024-11-20T21:27:37.220957Z",
     "iopub.status.idle": "2024-11-20T21:27:48.838794Z",
     "shell.execute_reply": "2024-11-20T21:27:48.837907Z",
     "shell.execute_reply.started": "2024-11-20T21:27:37.221783Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"WANDB_PROJECT\"] = \"Summarizer_v2\"\n",
    "os.environ[\"WANDB_SILENT\"] = \"true\"\n",
    "os.environ[\"WANDB_API_KEY\"] = \"\"\n",
    "\n",
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "import tqdm\n",
    "from datasets import Dataset, load_dataset\n",
    "import pandas as pd\n",
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments, TextStreamer, DataCollatorForSeq2Seq\n",
    "from unsloth import is_bfloat16_supported"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model in 4 bit and Specify Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:27:52.977687Z",
     "iopub.status.busy": "2024-11-20T21:27:52.976859Z",
     "iopub.status.idle": "2024-11-20T21:28:11.361619Z",
     "shell.execute_reply": "2024-11-20T21:28:11.360782Z",
     "shell.execute_reply.started": "2024-11-20T21:27:52.977652Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2024.11.7: Fast Llama patching. Transformers = 4.46.3.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.741 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.5.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.28.post3. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.11.7 patched 28 layers with 28 QKV layers, 28 O layers and 28 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Llama-3.2-3B-bnb-4bit\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")\n",
    "\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset and Map it with the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:28:15.149761Z",
     "iopub.status.busy": "2024-11-20T21:28:15.149074Z",
     "iopub.status.idle": "2024-11-20T21:28:15.307268Z",
     "shell.execute_reply": "2024-11-20T21:28:15.306259Z",
     "shell.execute_reply.started": "2024-11-20T21:28:15.149719Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "output_dir = \"/kaggle/working/\"\n",
    "train_data_path = '/kaggle/input/summarization/dialogue_summary_01/dialogue_summary_train.csv'\n",
    "val_data_path = '/kaggle/input/summarization/dialogue_summary_01/dialogue_summary_validation.csv'\n",
    "train_df = pd.read_csv(train_data_path)\n",
    "val_df = pd.read_csv(val_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:28:17.928599Z",
     "iopub.status.busy": "2024-11-20T21:28:17.927878Z",
     "iopub.status.idle": "2024-11-20T21:28:17.940745Z",
     "shell.execute_reply": "2024-11-20T21:28:17.939985Z",
     "shell.execute_reply.started": "2024-11-20T21:28:17.928565Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...</td>\n",
       "      <td>Mr. Smith's getting a check-up, and Doctor Haw...</td>\n",
       "      <td>get a check-up</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#: Hello Mrs. Parker, how have you bee...</td>\n",
       "      <td>Mrs Parker takes Ricky for his vaccines. Dr. P...</td>\n",
       "      <td>vaccines</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#: Excuse me, did you see a set of key...</td>\n",
       "      <td>#Person1#'s looking for a set of keys and asks...</td>\n",
       "      <td>find keys</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#: Why didn't you tell me you had a gi...</td>\n",
       "      <td>#Person1#'s angry because #Person2# didn't tel...</td>\n",
       "      <td>have a girlfriend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1#: Watsup, ladies! Y'll looking'fine t...</td>\n",
       "      <td>Malik invites Nikki to dance. Nikki agrees if ...</td>\n",
       "      <td>dance</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  #Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. ...   \n",
       "1  #Person1#: Hello Mrs. Parker, how have you bee...   \n",
       "2  #Person1#: Excuse me, did you see a set of key...   \n",
       "3  #Person1#: Why didn't you tell me you had a gi...   \n",
       "4  #Person1#: Watsup, ladies! Y'll looking'fine t...   \n",
       "\n",
       "                                             summary              topic  \n",
       "0  Mr. Smith's getting a check-up, and Doctor Haw...     get a check-up  \n",
       "1  Mrs Parker takes Ricky for his vaccines. Dr. P...           vaccines  \n",
       "2  #Person1#'s looking for a set of keys and asks...          find keys  \n",
       "3  #Person1#'s angry because #Person2# didn't tel...  have a girlfriend  \n",
       "4  Malik invites Nikki to dance. Nikki agrees if ...              dance  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:28:21.193697Z",
     "iopub.status.busy": "2024-11-20T21:28:21.193346Z",
     "iopub.status.idle": "2024-11-20T21:28:21.202815Z",
     "shell.execute_reply": "2024-11-20T21:28:21.201997Z",
     "shell.execute_reply.started": "2024-11-20T21:28:21.193666Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dialogue</th>\n",
       "      <th>summary</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>#Person1#: Hello, how are you doing today?\\n#P...</td>\n",
       "      <td>#Person2# has trouble breathing. The doctor as...</td>\n",
       "      <td>see a doctor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#Person1#: Hey Jimmy. Let's go workout later t...</td>\n",
       "      <td>#Person1# invites Jimmy to go workout and pers...</td>\n",
       "      <td>do exercise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#Person1#: I need to stop eating such unhealth...</td>\n",
       "      <td>#Person1# plans to stop eating unhealthy foods...</td>\n",
       "      <td>healthy foods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Person1#: Do you believe in UFOs?\\n#Person2#:...</td>\n",
       "      <td>#Person2# believes in UFOs and can see them in...</td>\n",
       "      <td>UFOs and aliens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#Person1#: Did you go to school today?\\n#Perso...</td>\n",
       "      <td>#Person1# didn't go to school today. #Person2#...</td>\n",
       "      <td>go to school</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            dialogue  \\\n",
       "0  #Person1#: Hello, how are you doing today?\\n#P...   \n",
       "1  #Person1#: Hey Jimmy. Let's go workout later t...   \n",
       "2  #Person1#: I need to stop eating such unhealth...   \n",
       "3  #Person1#: Do you believe in UFOs?\\n#Person2#:...   \n",
       "4  #Person1#: Did you go to school today?\\n#Perso...   \n",
       "\n",
       "                                             summary            topic  \n",
       "0  #Person2# has trouble breathing. The doctor as...     see a doctor  \n",
       "1  #Person1# invites Jimmy to go workout and pers...      do exercise  \n",
       "2  #Person1# plans to stop eating unhealthy foods...    healthy foods  \n",
       "3  #Person2# believes in UFOs and can see them in...  UFOs and aliens  \n",
       "4  #Person1# didn't go to school today. #Person2#...     go to school  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:30:33.140799Z",
     "iopub.status.busy": "2024-11-20T21:30:33.140434Z",
     "iopub.status.idle": "2024-11-20T21:30:33.399671Z",
     "shell.execute_reply": "2024-11-20T21:30:33.398777Z",
     "shell.execute_reply.started": "2024-11-20T21:30:33.140766Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e063739a03324621bf2f8490641547a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/12460 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b93485f566451d8c338b615c47d07b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt = \"\"\"Below is a dialogue. Generate only an abstractive summary and a topic for the dialogue (without including the dialogue in the response).\n",
    "\n",
    "### Dialogue:\n",
    "{}\n",
    "\n",
    "### Summary and Topic:\n",
    "Summary: {}\n",
    "Topic: {}\n",
    "\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token  # Must add EOS_TOKEN\n",
    "\n",
    "def formatting_prompts_func(examples):\n",
    "    dialogues = examples[\"dialogue\"]\n",
    "    summaries = examples[\"summary\"]\n",
    "    topics = examples[\"topic\"]\n",
    "    \n",
    "    texts = []\n",
    "    for dialogue, summary, topic in zip(dialogues, summaries, topics):\n",
    "        # Construct the prompt for training\n",
    "        input_text = dialogue\n",
    "        output_text = f\"Summary: {summary} Topic: {topic}\"\n",
    "        \n",
    "        # Ensure that EOS_TOKEN is added to avoid infinite generation\n",
    "        text = prompt.format(input_text, summary, topic) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "\n",
    "# Convert the pandas DataFrame to the Hugging Face dataset\n",
    "train_dataset = Dataset.from_pandas(train_df)\n",
    "train_dataset = train_dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "# Apply the same transformation to the validation dataset\n",
    "val_dataset = Dataset.from_pandas(val_df)\n",
    "val_dataset = val_dataset.map(formatting_prompts_func, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:30:40.178144Z",
     "iopub.status.busy": "2024-11-20T21:30:40.177149Z",
     "iopub.status.idle": "2024-11-20T21:30:40.182947Z",
     "shell.execute_reply": "2024-11-20T21:30:40.181914Z",
     "shell.execute_reply.started": "2024-11-20T21:30:40.178103Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialogue': \"#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\", 'summary': \"Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\", 'topic': 'get a check-up', 'text': \"Below is a dialogue. Generate only an abstractive summary and a topic for the dialogue (without including the dialogue in the response).\\n\\n### Dialogue:\\n#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\\n#Person2#: I found it would be a good idea to get a check-up.\\n#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\\n#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\\n#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\\n#Person2#: Ok.\\n#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\\n#Person2#: Yes.\\n#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\\n#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\\n#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\\n#Person2#: Ok, thanks doctor.\\n\\n### Summary and Topic:\\nSummary: Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\\nTopic: get a check-up\\n<|end_of_text|>\"}\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0])\n",
    "# print(val_dataset[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:30:42.835123Z",
     "iopub.status.busy": "2024-11-20T21:30:42.834782Z",
     "iopub.status.idle": "2024-11-20T21:30:42.858187Z",
     "shell.execute_reply": "2024-11-20T21:30:42.857223Z",
     "shell.execute_reply.started": "2024-11-20T21:30:42.835095Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is a dialogue. Generate only an abstractive summary and a topic for the dialogue (without including the dialogue in the response).\n",
      "\n",
      "### Dialogue:\n",
      "#Person1#: Hi, Mr. Smith. I'm Doctor Hawkins. Why are you here today?\n",
      "#Person2#: I found it would be a good idea to get a check-up.\n",
      "#Person1#: Yes, well, you haven't had one for 5 years. You should have one every year.\n",
      "#Person2#: I know. I figure as long as there is nothing wrong, why go see the doctor?\n",
      "#Person1#: Well, the best way to avoid serious illnesses is to find out about them early. So try to come at least once a year for your own good.\n",
      "#Person2#: Ok.\n",
      "#Person1#: Let me see here. Your eyes and ears look fine. Take a deep breath, please. Do you smoke, Mr. Smith?\n",
      "#Person2#: Yes.\n",
      "#Person1#: Smoking is the leading cause of lung cancer and heart disease, you know. You really should quit.\n",
      "#Person2#: I've tried hundreds of times, but I just can't seem to kick the habit.\n",
      "#Person1#: Well, we have classes and some medications that might help. I'll give you more information before you leave.\n",
      "#Person2#: Ok, thanks doctor.\n",
      "\n",
      "### Summary and Topic:\n",
      "Summary: Mr. Smith's getting a check-up, and Doctor Hawkins advises him to have one every year. Hawkins'll give some information about their classes and medications to help Mr. Smith quit smoking.\n",
      "Topic: get a check-up\n",
      "<|end_of_text|>\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset['text'][0])\n",
    "# print(val_dataset['text'][0]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:30:46.999133Z",
     "iopub.status.busy": "2024-11-20T21:30:46.998795Z",
     "iopub.status.idle": "2024-11-20T21:30:47.609264Z",
     "shell.execute_reply": "2024-11-20T21:30:47.608341Z",
     "shell.execute_reply.started": "2024-11-20T21:30:46.999102Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "exist_already = os.path.exists(output_dir)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = train_dataset,\n",
    "    eval_dataset = val_dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    data_collator = DataCollatorForSeq2Seq(tokenizer = tokenizer),\n",
    "    dataset_num_proc = 2,\n",
    "    packing = True,\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 10,\n",
    "        num_train_epochs = 1,\n",
    "        # max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = output_dir,\n",
    "        save_strategy = \"steps\",\n",
    "        save_steps = 5,\n",
    "        eval_steps= 10,\n",
    "        save_total_limit = 2,\n",
    "        report_to=\"wandb\"\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if(exist_already):\n",
    "    trainer_stats = trainer.train(resume_from_checkpoint=True)\n",
    "else:\n",
    "    trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T21:31:05.621572Z",
     "iopub.status.busy": "2024-11-20T21:31:05.621186Z",
     "iopub.status.idle": "2024-11-20T22:50:54.051634Z",
     "shell.execute_reply": "2024-11-20T22:50:54.050954Z",
     "shell.execute_reply.started": "2024-11-20T21:31:05.621543Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 1,655 | Num Epochs = 1\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 16 | Total steps = 103\n",
      " \"-____-\"     Number of trainable parameters = 24,313,856\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9930f5c925d4f02b4d2c7f77f8a5860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011119695122220542, max=1.0â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='103' max='103' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [103/103 1:18:52, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.710100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.555300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.464900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.423200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.403600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.402900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>1.416500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>1.385800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.392400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.375600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:50:54.053267Z",
     "iopub.status.busy": "2024-11-20T22:50:54.052992Z",
     "iopub.status.idle": "2024-11-20T22:50:54.884129Z",
     "shell.execute_reply": "2024-11-20T22:50:54.883254Z",
     "shell.execute_reply.started": "2024-11-20T22:50:54.053241Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/kaggle/working/llama_3_2_3B_summarizer_v3/tokenizer_config.json',\n",
       " '/kaggle/working/llama_3_2_3B_summarizer_v3/special_tokens_map.json',\n",
       " '/kaggle/working/llama_3_2_3B_summarizer_v3/tokenizer.json')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"/kaggle/working/llama_3_2_3B_summarizer_v3\")\n",
    "tokenizer.save_pretrained(\"/kaggle/working/llama_3_2_3B_summarizer_v3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:58:59.143703Z",
     "iopub.status.busy": "2024-11-20T22:58:59.143329Z",
     "iopub.status.idle": "2024-11-20T22:58:59.150840Z",
     "shell.execute_reply": "2024-11-20T22:58:59.149913Z",
     "shell.execute_reply.started": "2024-11-20T22:58:59.143671Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Load the model and prepare it for inference (only done once)\n",
    "model = FastLanguageModel.for_inference(model)\n",
    "\n",
    "def generate_summary(user_input, max_new_tokens=256):\n",
    "    # Preprocess the input to fit the prompt format\n",
    "    summarization_prompt = \"\"\"Below is a dialogue. Generate only an abstractive summary and a topic for the dialogue (without including the dialogue in the response).\n",
    "\n",
    "        ### Dialogue:\n",
    "        {}\n",
    "        \n",
    "        ### Summary and Topic:\n",
    "        \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        [\n",
    "            summarization_prompt.format(user_input)  # Insert the user input (article) into the prompt\n",
    "        ], return_tensors=\"pt\"\n",
    "    ).to(\"cuda\")  # Move inputs to GPU if available\n",
    "\n",
    "    # Initialize the text streamer to handle model output\n",
    "    text_streamer = TextStreamer(tokenizer)\n",
    "\n",
    "    # Generate the summary\n",
    "    _ = model.generate(\n",
    "        **inputs,\n",
    "        streamer=text_streamer,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        use_cache=True,\n",
    "        temperature=0.4,  # randomness\n",
    "        top_p=0.9,  # nucleus sampling for better coherence\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-11-20T22:59:03.372078Z",
     "iopub.status.busy": "2024-11-20T22:59:03.371147Z",
     "iopub.status.idle": "2024-11-20T22:59:09.709487Z",
     "shell.execute_reply": "2024-11-20T22:59:09.708620Z",
     "shell.execute_reply.started": "2024-11-20T22:59:03.372042Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is a dialogue. Generate only an abstractive summary and a topic for the dialogue (without including the dialogue in the response).\n",
      "\n",
      "        ### Dialogue:\n",
      "        \n",
      "#Deepak#: \"I've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me.\"\n",
      "#SurvUday#: \"Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on?\"\n",
      "#Deepak#: \"I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me.\"\n",
      "#SurvUday#: \"I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work?\"\n",
      "#Deepak#: \"Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being.\"\n",
      "#SurvUday#: \"It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload?\"\n",
      "#Deepak#: \"I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle.\"\n",
      "#SurvUday#: \"It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together.\"\n",
      "#Deepak#: \"You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable?\"\n",
      "#SurvUday#: \"It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this.\"\n",
      "#Deepak#: \"Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance.\"\n",
      "#SurvUday#: \"You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this!\"\n",
      "\n",
      "        \n",
      "        ### Summary and Topic:\n",
      "         #Person1# tells #Person2# #Person1# feels overwhelmed lately because of the added responsibilities and pressure at work. #Person1# also tells #Person2# #Person1# has been trying to prioritize tasks and delegate whenever possible. #Person1# asks #Person2# how to approach the discussion with #Person1#'s supervisor or a trusted colleague without feeling vulnerable.\n",
      "         Summary and Topic: discuss work challenges and approach the discussion with supervisor\n",
      "<|end_of_text|>\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Test the function\n",
    "user_input = \"\"\"\n",
    "#Deepak#: \"I've been feeling so sad and overwhelmed lately. Work has become such a massive source of stress for me.\"\n",
    "#SurvUday#: \"Hey there, I'm here to listen and support you. It sounds like work has been really challenging lately. Can you tell me more about what's been going on?\"\n",
    "#Deepak#: \"I recently got a promotion at work, which I thought would be exciting. But the added responsibilities and pressure have just taken a toll on my mental health. It's been a really moving experience for me.\"\n",
    "#SurvUday#: \"I can understand how it can be overwhelming when we're faced with higher expectations. It's okay to acknowledge your emotions and allow yourself to feel sad in this situation. It's an important part of the healing process. What specific challenges have you been facing at work?\"\n",
    "#Deepak#: \"Well, the workload has increased significantly, and I find it hard to maintain a work-life balance. I've been staying late at the office, and it feels like I'm constantly under a pile of never-ending tasks. It's just so hard to keep up, and it's impacting my overall well-being.\"\n",
    "#SurvUday#: \"It sounds like you're dealing with a lot of pressure to perform and succeed. Remember, it's crucial to take care of yourself, both mentally and physically. A healthy work-life balance is essential. Have you tried any strategies to cope with the added workload?\"\n",
    "#Deepak#: \"I've been trying to prioritize my tasks and delegate whenever possible. I've also started practicing meditation during my breaks to help manage stress. But sometimes, it feels like no matter what I do, I can't catch a break. It's been a constant struggle.\"\n",
    "#SurvUday#: \"It's great to hear that you're already implementing some helpful strategies. Remember, progress takes time, and it's okay to have setbacks. In addition to what you're already doing, I encourage you to also communicate with your supervisor or team about your workload and discuss possible solutions together.\"\n",
    "#Deepak#: \"You're right. I haven't really opened up about my struggles to my coworkers or supervisor. I guess I've been afraid of appearing weak or incapable. How can I approach this discussion without feeling vulnerable?\"\n",
    "#SurvUday#: \"It's completely normal to feel that way, but remember, asking for support is a strength, not a weakness. Start by scheduling a conversation with your supervisor or a trusted colleague in a private and comfortable setting. Be honest about your challenges and express your willingness to find solutions together. Remember, you're not alone in this.\"\n",
    "#Deepak#: \"Thank you for your understanding and guidance. I appreciate the reminder that I don't have to face this alone. I'll gather my courage and initiate that conversation soon. I need to prioritize my well-being and find a healthier balance.\"\n",
    "#SurvUday#: \"You're very welcome! I'm here to support you every step of the way. Taking care of yourself should always be a priority. Remember to be kind to yourself and celebrate your progress, no matter how small it may seem. You've got this!\"\n",
    "\"\"\"\n",
    "\n",
    "# Call the function to generate the summary and topic\n",
    "print(generate_summary(user_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Push Model to Huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "Token = \"\" # Huggingface Token\n",
    "Repo = \"dkp2701/summarizer_v3\" # Model Repo\n",
    "model.push_to_hub_gguf(Repo,\n",
    "                        tokenizer,\n",
    "                        quantization_method = [\"q4_k_m\"],\n",
    "                        token = Token)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6130639,
     "sourceId": 9965968,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
